{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet+augmen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3T+qdSU4/ICGXHFLgiM9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohdrahil7/image-Segmentation/blob/master/unet%2Baugmen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIGgdJ_ABY6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3703625a-0284-4fc4-d0fa-d7721d7e8c5e"
      },
      "source": [
        "#training the unet architecture along with data augmentation\n",
        "#training and testing on color images of real size\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0XfaMEHBuJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe5fedab-d4b7-4562-c271-7afacc52c15a"
      },
      "source": [
        "#implementation of fcn-8 code\n",
        "from keras.layers import *\n",
        "from keras import Model\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZBQpJ4mCFFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2LEw_7NiMEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VJ9OP59iOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3afpWrkiQoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading the training data \n",
        "#reading x and y data\n",
        "x=np.load('Skin_TestX.npy')\n",
        "y=np.load('Skin_TestY.npy')\n",
        "#reading the test_data\n",
        "x_test=np.load('Skin_ValidX.npy')\n",
        "y_test=np.load('Skin_ValidY.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReXfBZQMfYjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x,validx,y,validy=train_test_split(x,y,test_size=0.2,random_state=28,shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wto_pK6KkR4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1f404e01-9ee6-447f-bd96-4a5d3a2fdd78"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(validx.shape)\n",
        "print(validy.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(480, 192, 256, 3)\n",
            "(480, 192, 256, 1)\n",
            "(120, 192, 256, 3)\n",
            "(120, 192, 256, 1)\n",
            "(150, 192, 256, 3)\n",
            "(150, 192, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFwircjYkfQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "76db2a9f-d98a-4ae0-a7c3-e8872cf2df77"
      },
      "source": [
        "#reshaping\n",
        "y=y.reshape(-1,192,256,1)\n",
        "validy=validy.reshape(-1,192,256,1)\n",
        "y_test=y_test.reshape(-1,192,256,1)\n",
        "print(y.shape)\n",
        "print(validy.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(480, 192, 256, 1)\n",
            "(120, 192, 256, 1)\n",
            "(150, 192, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0epI6Lzxkhjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#performing the normalization of taking each value between 0 and 1\n",
        "y=y.astype('float32')/255\n",
        "y_test=y_test.astype('float32')/255\n",
        "validy=validy.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xtFwJy4kkM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing the training data\n",
        "x_mean=np.mean(x)\n",
        "x_std=np.std(x)\n",
        "x=x-x_mean\n",
        "x=x/x_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjQ-4dF1hlBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing validation data\n",
        "validx=validx-x_mean\n",
        "validx=validx/x_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1LOXGtlknZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing test data\n",
        "x_test=x_test-x_mean\n",
        "x_test=x_test/x_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_2bGcvwksRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen=ImageDataGenerator(featurewise_center=False,samplewise_center=False,rotation_range=30,featurewise_std_normalization=False,\n",
        "                           samplewise_std_normalization=False,horizontal_flip=True,zoom_range=[0.8,0.9])\n",
        "#creating augmented image for both x image and y image\n",
        "img_datagen=ImageDataGenerator(datagen)\n",
        "img_mask=ImageDataGenerator(datagen)\n",
        "bs=32 #creating batch size of 32\n",
        "seed=215"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MilhZS2Ynpbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_gen=img_datagen.flow(x,batch_size=bs,seed=seed,shuffle=True)\n",
        "mask_gen=img_mask.flow(y,batch_size=bs,seed=seed,shuffle=True)\n",
        "#putting both x and y augmented images into one zip flip\n",
        "img_zip=zip(img_gen,mask_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppL9S-coryyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "522a14b3-286d-4bfa-890a-9cad1870faf8"
      },
      "source": [
        "#creating a Unet Network but since we are not creating the sequentail network so we need model API to create model\n",
        "\n",
        "def create_model():\n",
        "  input_img=Input(shape=(192,256,3))\n",
        "  \n",
        "  #block_1\n",
        "  z=Conv2D(32,(3,3),padding='same',input_shape=(128,128,1),activation='relu',name='block1_conv1')(input_img)\n",
        "  conv1=Conv2D(32,(3,3),padding='same',activation='relu',name='block1_conv2')(z)\n",
        "  z=MaxPool2D(pool_size=(2,2),strides=(2,2),name='block1_maxpooling')(conv1)\n",
        "\n",
        "  #block_2\n",
        "  z=Conv2D(64,(3,3),padding='same',activation='relu',name='block2_conv1')(z)\n",
        "  conv2=Conv2D(64,(3,3),padding='same',activation='relu',name='block2_conv2')(z)\n",
        "  z=MaxPool2D(pool_size=(2,2),strides=(2,2),name='block2_maxpooling')(conv2)\n",
        "\n",
        "  #block_3\n",
        "  z=Conv2D(128,(3,3),padding='same',activation='relu',name='block3_conv1')(z)\n",
        "  z=Conv2D(128,(3,3),padding='same',activation='relu',name='block3_conv2')(z)\n",
        "  up1=Conv2DTranspose(128,(2,2),strides=(2,2),activation='relu',padding='same',name='upsampling')(z)\n",
        "\n",
        "  concat1=concatenate([up1,conv2])\n",
        "  #block_4\n",
        "  z=Conv2D(64,(3,3),padding='same',activation='relu',name='block4_conv1')(concat1)\n",
        "  z=Conv2D(64,(3,3),padding='same',activation='relu',name='block4_conv2')(z)\n",
        "  up2=Conv2DTranspose(64,(2,2),strides=(2,2),activation='relu',padding='same',name='upsampling2')(z)\n",
        "  \n",
        "  concat2=concatenate([up2,conv1])\n",
        "  #block_5\n",
        "  z=Conv2D(32,(3,3),padding='same',activation='relu',name='block5_conv1')(concat2)\n",
        "  z=Conv2D(32,(3,3),padding='same',activation='relu',name='block5_conv2')(z)\n",
        "  z=Dropout(0.5)(z)\n",
        "  final=Conv2D(1,(1,1),activation='relu',padding='same' ,name='final')(z)\n",
        "\n",
        "  model1=Model(input_img,final)\n",
        "  return model1\n",
        "\n",
        "model=create_model()\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 192, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 192, 256, 32) 896         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 192, 256, 32) 9248        block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_maxpooling (MaxPooling2D (None, 96, 128, 32)  0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 96, 128, 64)  18496       block1_maxpooling[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 96, 128, 64)  36928       block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_maxpooling (MaxPooling2D (None, 48, 64, 64)   0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 48, 64, 128)  73856       block2_maxpooling[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 48, 64, 128)  147584      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "upsampling (Conv2DTranspose)    (None, 96, 128, 128) 65664       block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 96, 128, 192) 0           upsampling[0][0]                 \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 96, 128, 64)  110656      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 96, 128, 64)  36928       block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "upsampling2 (Conv2DTranspose)   (None, 192, 256, 64) 16448       block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 192, 256, 96) 0           upsampling2[0][0]                \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 192, 256, 32) 27680       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 192, 256, 32) 9248        block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 192, 256, 32) 0           block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "final (Conv2D)                  (None, 192, 256, 1)  33          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 553,665\n",
            "Trainable params: 553,665\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anedUqagr82p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akdf-lxasBn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQQhYJvisGJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating callbacks\n",
        "#creating the callbacks and checkpoints to save best model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "es=EarlyStopping(monitor=\"val_loss\",mode='min',patience=10 ,verbose=1)\n",
        "cp=ModelCheckpoint('Unet_color_aug.h5',monitor=\"val_loss\",mode='min',verbose=1,save_best_only='true')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmcIJ8rQsKgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "510fda03-3c9d-478c-916c-8093d7cdc96f"
      },
      "source": [
        "history=model.fit_generator(datagen.flow(x,y,batch_size=32,seed=bs),epochs=100,callbacks=([es,cp]),validation_data=(validx,validy),steps_per_epoch=(len(x)//bs))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 7s 439ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.00000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 6s 422ms/step - loss: 3.5118e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.5118e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 3.5118e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 3.5118e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00000\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00000\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00000\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 3.5117e-06 - accuracy: 0.7717 - val_loss: 4.1031e-06 - val_accuracy: 0.7332\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00000\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewsQ_u85sYn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}